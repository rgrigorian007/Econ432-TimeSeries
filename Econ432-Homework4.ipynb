{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Econ 432 Homework 4\n",
    "author: \"Richard Grigorian (UID: 505-088-797)\"\n",
    "date: today\n",
    "format: \n",
    "    html:\n",
    "        mainfont: \"Linux Libertine 0\"\n",
    "        fontsize: medium\n",
    "        number-sections: true\n",
    "        number-depth: 3\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        code-fold: false\n",
    "        html-math-method: katex\n",
    "        embed-resources: false\n",
    "        self-contained-math: false\n",
    "    pdf:\n",
    "        mainfont: Times New Roman\n",
    "        sansfont: Times New Roman\n",
    "        number-sections: True\n",
    "        number-depth: 2\n",
    "        toc: true\n",
    "        toc-depth: 3\n",
    "        toc-title: Contents\n",
    "        shift-heading-level-by: 0\n",
    "        execute:\n",
    "            warning: false\n",
    "            cache: true\n",
    "        code:\n",
    "        code-block-bg: true\n",
    "        code-block-border-left: \"#eeeeee\"\n",
    "        highlight-style: tango\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< pagebreak >}}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Review Questions\n",
    "\n",
    "## Problem 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the risk of a stock, a sample of 73 cc returns was taken and the sample standard devation $\\hat{\\sigma}$ was 0.057. To get a confidence interval for the true standard deviation $\\sigma$, 10,000 resamples were taken. Let $\\hat{\\sigma}_{b, boot}$ were sorted and the table below contains selected values of $\\hat{\\sigma}_{b, boot}$ ranked from smallest to alrgest (so rank 1 is the smallest and so forth).\n",
    "\n",
    "| Rank | Value of $\\hat{\\sigma}_{b, boot}$ |\n",
    "| :---: | :---: |\n",
    "| 250 | 0.047 |\n",
    "| 500 | 0.049 |\n",
    "| 2500 | 0.053 |\n",
    "| 7500 | 0.060 |\n",
    "| 9500 | 0.065 |\n",
    "| 9750 | 0.067 |\n",
    "\n",
    "### Part (a)\n",
    "\n",
    "Find the bootstrap standard error of $\\hat{\\sigma}$.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the given info, we can infer that we should use the *quantile bootstrap* method for estimating standard error. Recall the expression for this technique is:\n",
    "$$\\operatorname{SE}_{q - bt}(\\hat{\\theta}) = \\frac{\\hat{\\theta}^*_{[\\alpha_1]} - \\hat{\\theta}^*_{[\\alpha_2]}}{z_{\\alpha_1} - z_{\\alpha_2}}$$\n",
    "where $z_{\\alpha_1}$ and $z_{\\alpha_2}$ denote the $\\alpha_1$ and $\\alpha_2$ quantiles of the standard normal distribution. In practiace, we often choose the 75th and 25th percentiles respectively.\n",
    "\n",
    "Therefore, we apply this expression to the above problem. To find the normal distribution quantiles we use `python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_1 = 0.6744897501960817\n",
      "alpha_2 = -0.6744897501960817\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "alpha1 = norm.ppf(0.75)\n",
    "alpha2 = norm.ppf(0.25)\n",
    "print('alpha_1 =', alpha1)\n",
    "print('alpha_2 =', alpha2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_stdv = (0.06 - 0.053) / (alpha1 - alpha2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This then gives us:\n",
    "$$\\operatorname{SE}_{q - bt}(\\hat{\\sigma}) = \\frac{0.060 - 0.053}{0.674 - (-0.0674)} = 0.005189$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "\n",
    "Find the 90% and 95% confidence intervals using the bootstrap standard error in part (a) and the asymptotic normal distribution of $\\hat{\\sigma}$.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "The confidence interval expression is:\n",
    "$$ 1 - \\alpha \\ \\%\\operatorname{CI:} \\ \\bigg [ \\hat{\\sigma} - \\operatorname{SE}_{q - bt}(\\hat{\\sigma}) z_{1 - \\alpha / 2}\\ , \\ \\hat{\\sigma} + \\operatorname{SE}_{q - bt}(\\hat{\\sigma}) z_{1 - \\alpha / 2} \\bigg]$$\n",
    "At the 90% level, this would be:\n",
    "$$ \\operatorname{90 \\% \\ CI:} \\ \\big [ 0.057 \\pm  1.645 (0.005189) \\big] = \\big [0.0485 \\ , \\ 0.0655 \\big]$$\n",
    "At the 95% level, this would be:\n",
    "$$ \\operatorname{95 \\% \\ CI:} \\ \\big [ 0.057 \\pm  1.96 (0.005189) \\big] = \\big [0.0468 \\ , \\ 0.0672 \\big]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "\n",
    "Find the 90% and 95% equal tail bootstrap confidence interval for $\\sigma$.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "To construct an equal tail bootstrap confidence interval we need\n",
    "$$ \\big [ \\hat{\\sigma} + c^*_{T,\\alpha/2} \\ , \\ \\hat{\\sigma} + c^*_{T, 1-\\alpha/2} \\big]$$\n",
    "where $c^*_{T,\\alpha/2}$ is the $\\alpha$ qunatile of $\\{ \\hat{\\sigma} - \\hat{\\sigma}^{*,b} \\}^B_{b=1}$. Conceptually, now the lowest rank value will have the largest difference. Therefore, the ranks for the differences will be somewhat flipped. Therfore, at the 90% level this would be:\n",
    "$$ \\operatorname{90 \\% \\ Equal \\ Tail \\ CI:} \\big [ 0.057 + (0.057 - 0.065) \\ , \\ 0.057 + (0.057 - 0.049) \\big] = \\big [0.049 \\ , \\ 0.065 \\big ]$$\n",
    "At the 95% level, this would be:\n",
    "$$ \\operatorname{95 \\% \\ Equal \\ Tail \\ CI:} \\big [ 0.057 + (0.057 - 0.067) \\ , \\ 0.057 + (0.057 - 0.047)\\big] = \\big [0.047 \\ , \\ 0.067 \\big ]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "In the following Python program, resampling was used to estimate the bias and variance of the sample correlation between the variables in the vectors $x$ and $y$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "samplecor = np.corrcoef(x,y)[0,1]\n",
    "n = len(x)\n",
    "nboot = 5000\n",
    "resamplecor = np.zeros(nboot)\n",
    "for b in range(nboot):\n",
    "    ind = np.random.choice(np.arrange(0,n,1),\n",
    "                    replace = True, size = n)\n",
    "    resamplecor[b] = np.corrcoef(x[ind], y[ind])[0,1]\n",
    "print(samplecor)\n",
    "print(np.mean(resamplecor))\n",
    "print(np.std(resamplecor, ddof = 1))\n",
    "```\n",
    "\n",
    "The output is\n",
    "\n",
    "```\n",
    "> n\n",
    "[1] 20\n",
    "> samplecor\n",
    "[1] 0.69119\n",
    "> np.mean(resamplecor)\n",
    "[1] 0.68431\n",
    "> np.std(resamplecor, ddof = 1)\n",
    "[1] 0.11293\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "\n",
    "Estimate the bias of the sample correlation coefficient.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "Recall that bias is simply the difference between our estimate and the true parameter. Hence, the bias of the sample correlation coefficient under bootstrap is:\n",
    "$$\\operatorname{Bias}(\\rho, \\hat{\\rho}) = \\mathbb{E}[\\hat{\\rho}] - \\rho = \\bar{\\hat{\\rho}^*} - \\hat{\\rho} = 0.68431 - 0.69119 = -0.00688$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "\n",
    "Estimate the standard deviation of the sample correlation coefficient.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "From the above printout, see that the standard deviation of our boostrapped sample correlations is equal to 0.11293. Hence, **the standard deviation of the sample correlation coefficient is 0.11293**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "\n",
    "Estimate the MSE of the sample correlation coefficient\n",
    "\n",
    "#### Solution\n",
    "\n",
    "MSE is defined as\n",
    "$$\\text{MSE} = B^{-1} \\sum_{b=1}^B \\big ( \\hat{\\theta}^{*,b} - \\hat{\\theta} \\big )^2$$\n",
    "With the output above, it would be most convienent to reform MSE using the Bias-Variance decomposition:\n",
    "$$\\operatorname{MSE}(\\hat{\\theta}^{*,b}, \\hat{\\theta}) = \\big ( \\operatorname{Bias}(\\hat{\\theta}^{*,b}, \\hat{\\theta}) \\big )^2 + \\operatorname{Var}(\\hat{\\theta}^{*,b})$$\n",
    "We have both of these values since variance is just the square of standard deviation. Hence, the MSE of our sample correlation coefficient is:\n",
    "$$\\operatorname{MSE} = (-0.00688)^2 + (0.11293)^2 \\approx 0.0128$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "\n",
    "What fraction of the MSE is due to bias? How serious is the bias? Should something be done to reduce the bias? Explain your answer.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "To find the fraction of MSE due to bias, we simply look at our Bias-Variance decomposition once more. It is constructed of Bias and Variance; however, the Bias is squared so we have to account for that when computing the fraction. Therefore, the fraction of MSE due to bias is:\n",
    "$$\\frac{\\big ( \\operatorname{Bias}(\\hat{\\theta}^{*,b}, \\hat{\\theta}) \\big )^2}{\\operatorname{MSE}(\\hat{\\theta}^{*,b}, \\hat{\\theta})} = \\frac{(-0.00688)^2}{0.0128} \\approx 0.0037$$\n",
    "That means that about 0.37% of the MSE is coming from bias. That is not a very large number, in comparison to the variance which accounts for about 99.63% of the MSE. Therefore, while bootstrap bias tends to over-estimate the true moment, it seems to be a fairly minimal issue here. Rather, Variance is the dominant cause of the MSE; hence, we could take steps to reduce the variance at the cost of introducing a bit more bias. That being said, boostrap standard deviation also often over-estimates the true moment, so it is possible that our MSE is actually lower than what we found here.\n",
    "\n",
    "But in short, the bias is not very serious here and we do not need to reduce it further."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Python Exercises\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "This exercise uses weekly data in Apple from the first week of January, 2010 to the last week of January, 2021. Use the adjusted closing prices to compute weekly cc returns. Assume that the returns are i.i.d., even though there may be some autocorrelation and volatility clustering is likely. In bootstrap, let $B = 1000$ and set the random seed to 432 i.e., `np.random.seed(432)` in `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Initial Imports\n",
    "import yfinance as yf # pandas_datareader yahoo api not working\n",
    "import numpy as np\n",
    "from scipy.stats import iqr, norm\n",
    "\n",
    "# Import Data\n",
    "df = yf.download(\"AAPL\",\n",
    "                start = \"2010-01-01\",\n",
    "                end = \"2021-01-31\", \n",
    "                interval = '1wk')\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CC return\n",
    "Ret = np.log(df['Adj Close']/df['Adj Close'].shift(1))\n",
    "Ret = np.array(Ret)[1:] # Pass into array\n",
    "T = len(Ret)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "\n",
    "Find the sample mean and sample variance of the cc return, and also their standard errors (SEs) using the formula provided in the slides of statistical inference\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample mean is 0.005212\n",
      "The sample variance is 0.001375\n",
      "The standard error of mu_hat is 0.001542\n",
      "The standard error of sig2_hat is 0.000081\n"
     ]
    }
   ],
   "source": [
    "mu_h = np.mean(Ret) # Sample mean\n",
    "sig2_h = np.var(Ret, ddof = 1)  # Sample variance\n",
    "sd_mu = np.sqrt(sig2_h/T) # Standard error of mu_h\n",
    "sd_sig2 = sig2_h * np.sqrt(2/T) # Standard error of sig2_h\n",
    "\n",
    "# Print and round to six decimals\n",
    "print(\"The sample mean is %.6f\" % mu_h)\n",
    "print(\"The sample variance is %.6f\" % sig2_h)\n",
    "print(\"The standard error of mu_hat is %.6f\" % sd_mu)\n",
    "print(\"The standard error of sig2_hat is %.6f\" % sd_sig2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "\n",
    "Find the bootsrap SEs (the bootstrap SEs and the bootstrap IQR SEs) of the sample mean and the sample variance. Compare the bootstrap SEs with the SEs in part (a). Are they very different from each other for the same estimator (i.e., the sample mean and the sample variance)?\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(432) # Set seed\n",
    "B = 1000 # Number of bootstrap samples\n",
    "boot_samples = np.zeros((T,B)) # Initialize \n",
    "for b in range(B):\n",
    "    # random sample at each iteration\n",
    "    boot_samples[:, b] = np.random.choice(\n",
    "        Ret,\n",
    "        replace = True,\n",
    "        size = T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstrap SE of mu_hat is 0.001556\n",
      "The IQR SE of mu_hat is 0.001572\n"
     ]
    }
   ],
   "source": [
    "# Sample metrics for each iteration [Mean]\n",
    "boot_means = np.mean(boot_samples, axis = 0)\n",
    "B_SE_mu = np.std(boot_means, ddof = 1)\n",
    "\n",
    "IQR_SE_mu = iqr(\n",
    "    boot_means, interpolation = 'linear' # for boudnary values\n",
    "    )/(norm.ppf(0.75) - norm.ppf(0.25))\n",
    "\n",
    "print(\"The bootstrap SE of mu_hat is %.6f\" % B_SE_mu)\n",
    "print(\"The IQR SE of mu_hat is %.6f\" % IQR_SE_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstrap SE of sig2_hat is 0.000114\n",
      "The IQR SE of sig2_hat is 0.000109\n"
     ]
    }
   ],
   "source": [
    "# Sample metrics for each iteration [Variance]\n",
    "boot_vars = np.var(boot_samples, ddof = 1, axis = 0)\n",
    "B_SE_sig2 = np.std(boot_vars, ddof = 1)\n",
    "IQR_SE_sig2 = iqr(\n",
    "    boot_vars, interpolation = 'linear'\n",
    "    )/(norm.ppf(0.75) - norm.ppf(0.25))\n",
    "\n",
    "print(\"The bootstrap SE of sig2_hat is %.6f\" % B_SE_sig2)\n",
    "print(\"The IQR SE of sig2_hat is %.6f\" % IQR_SE_sig2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the standard error of the sample mean, we see that the bootstrap estimation provides a slightly larger estimate (which is to be expected). And for the standard error of the sample variance, we see similar results with the bootstrap technique delivering a larger standard error. In both instances, the two techniques are different. Although, they are not *very* different as they are similar values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "\n",
    "Find the bootstrap SEs (the bootstrap SEs and the bootstrap IQR SEs) of the sample standard deviation.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "This follows a very similar process to part (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstrap SE of sig_hat is 0.001539\n",
      "The IQR SE of sig_hat is 0.001471\n"
     ]
    }
   ],
   "source": [
    "# SE of St. Dev.\n",
    "boot_sds = np.std(boot_samples, ddof = 1, axis = 0)\n",
    "B_SE_sig = np.std(boot_sds, ddof = 1)\n",
    "IQR_SE_sig = iqr(\n",
    "    boot_sds, interpolation = 'linear'\n",
    "    )/(norm.ppf(0.75) - norm.ppf(0.25))\n",
    "\n",
    "print(\"The bootstrap SE of sig_hat is %.6f\" % B_SE_sig)\n",
    "print(\"The IQR SE of sig_hat is %.6f\" % IQR_SE_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "\n",
    "Estimate the bias and the mean square error of the sample standard deviation using bootstrap.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "Here we do not need to use the Bias-Variance Decomposition since we have all of the data. Rather, we can just use our bootstrap standard deviation and our sample standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstrap bias of sig_hat is -0.000140\n",
      "The bootstrap MSE of sig_hat is 0.000002\n"
     ]
    }
   ],
   "source": [
    "sig_h = np.std(Ret, ddof = 1) # Sample St. Dev\n",
    "B_Bias_sig = np.mean(boot_sds) - sig_h # Bias Calculation\n",
    "B_MSE_sig = np.mean((boot_sds - sig_h) ** 2) # MSE\n",
    "\n",
    "print(\"The bootstrap bias of sig_hat is %.6f\" % B_Bias_sig)\n",
    "print(\"The bootstrap MSE of sig_hat is %.6f\" % B_MSE_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e)\n",
    "\n",
    "Construct the equal tail and the symmetric 95% bootstrap confidence intervals of the standard deviation of the cc return.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Equal Tail CI:  [0.03416604242617804, 0.04017247446202637]\n",
      "95% Symmetric CI:  [0.03409684899894767, 0.04005717279480623]\n"
     ]
    }
   ],
   "source": [
    "# Quantiles of the difference (refer to formula)\n",
    "q_et_1 = np.quantile(sig_h - boot_sds, 0.025)\n",
    "q_et_2 = np.quantile(sig_h - boot_sds, 0.975)\n",
    "q_sym = np.quantile(np.abs(boot_sds - sig_h ), 0.95)\n",
    "\n",
    "print(\"95% Equal Tail CI: \", [sig_h + q_et_1, sig_h + q_et_2])\n",
    "print(\"95% Symmetric CI: \", [sig_h - q_sym, sig_h + q_sym])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (f)\n",
    "\n",
    "Suppose we invest \\$1000 on Apple for one week. Find the parametric and nonparametric estimators of VaR(0.1) and ES(0.1) for this investment. for the parametric estimator, you shall assume that returns are normally distributed.\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = 1000 # Initial wealth\n",
    "q1 = norm.ppf(0.1, loc = mu_h, scale = sig_h) # Parametric (Norm)\n",
    "q2 = np.quantile(Ret, 0.1, method = 'linear') # Nonparametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parametric estimate of VaR(0.1) is -41.421690\n",
      "The nonparametric estimate of VaR(0.1) is -38.195415\n"
     ]
    }
   ],
   "source": [
    "VaR_1 = W0 * (np.exp(q1) - 1)\n",
    "VaR_2 = W0 * (np.exp(q2) - 1)\n",
    "\n",
    "print(\"The parametric estimate of VaR(0.1) is %.6f\" % VaR_1)\n",
    "print(\"The nonparametric estimate of VaR(0.1) is %.6f\" % VaR_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the nonparametric estimate of the VaR is more conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametric ES\n",
    "nsim = 500000\n",
    "r_B = norm.rvs(\n",
    "    loc = mu_h, \n",
    "    scale = sig_h, \n",
    "    size = nsim, \n",
    "    random_state = 432)\n",
    "L_B = W0 * (np.exp(r_B) - 1)\n",
    "I_B = (L_B <= VaR_1) * 1\n",
    "ES_1 = np.mean(L_B * I_B)/np.mean(I_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parametric estimate of ES(0.1) is -57.901513\n",
      "The nonparametric estimate of ES(0.1) is -62.535302\n"
     ]
    }
   ],
   "source": [
    "# Nonparametric ES\n",
    "L_1 = W0 * (np.exp(Ret) - 1)\n",
    "I_1 = (L_1 <= VaR_2)\n",
    "ES_2 = np.mean(L_1 * I_1)/np.mean(I_1)\n",
    "\n",
    "print(\"The parametric estimate of ES(0.1) is %.6f\" % ES_1)\n",
    "print(\"The nonparametric estimate of ES(0.1) is %.6f\" % ES_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (g)\n",
    "\n",
    "Find the bootstrap SEs (the bootstrap SEs and the bootstrap IQR SEs) of the nonparametric estimators of VaR(0.1) and ES(0.1) in part (f).\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR function\n",
    "def VaR(y, p = 0.1, W0 = W0):\n",
    "    mu = np.mean(y)\n",
    "    q = np.quantile(y, p, method = 'linear')\n",
    "    return W0 * (np.exp(q) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Function\n",
    "def boot(data, func, nboot=5000, n=T):\n",
    "    \"\"\"\n",
    "    func: function, VaR or ES\n",
    "    nboot: number of bootstrap samples\n",
    "    n: size of a boostrap sample\n",
    "    \"\"\"\n",
    "    result = np.zeros(nboot)\n",
    "    for i in range(nboot):\n",
    "        boot_sample = np.random.choice(data, replace = True, size = n)\n",
    "        result[i] = func(boot_sample)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap SE (nonparametric estimator) of VaR(0.1): 2.580610\n",
      "Bootstrap IQR SE (nonparametric estimator) of VaR(0.1): 2.531376\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(432) # Set seed\n",
    "\n",
    "VaR_est = VaR(Ret) # VaR of cc returns\n",
    "\n",
    "# Bootstrap VaR & SE\n",
    "boot_VaR = boot(data = Ret, func = VaR)\n",
    "BootSE_VaR = np.std(boot_VaR, ddof = 1)\n",
    "\n",
    "# Bootstrap IQR SE\n",
    "Boot_IQR_SE_VaR = (np.quantile(boot_VaR, 0.75) - np.quantile(boot_VaR, 0.25)\n",
    "                   )/(norm.ppf(0.75) - norm.ppf(0.25))\n",
    "\n",
    "print(\"Bootstrap SE (nonparametric estimator) VaR(0.1): %.6f\" % BootSE_VaR)\n",
    "print(\"Bootstrap IQR SE (nonparametric estimator) VaR(0.1): %.6f\" % Boot_IQR_SE_VaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ES function\n",
    "def ES(y, p=0.1, W0 = W0):\n",
    "    mu = np.mean(y)\n",
    "    q = np.quantile(y, p, method = 'linear')\n",
    "    VaR_np = W0 * (np.exp(q) - 1)\n",
    "    L_1 = W0 * (np.exp(y) - 1)\n",
    "    I_1 = (L_1 <= VaR_np) * 1\n",
    "    return np.mean(L_1 * I_1)/np.mean(I_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap SE (nonparametric estimator) ES(0.1): 4.400157\n",
      "Bootstrap IQR SE (nonparametric estimator) ES(0.1): 4.430407\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(432) # Set seed\n",
    "\n",
    "ES_est = ES(Ret) # ES of cc returns\n",
    "\n",
    "# Bootstrap ES & SE\n",
    "boot_ES = boot(data = Ret, func = ES)\n",
    "BootSE_ES = np.std(boot_ES, ddof = 1)\n",
    "\n",
    "# Bootstrap IQR SE\n",
    "Boot_IQR_SE_ES = (np.quantile(boot_ES, 0.75) - np.quantile(boot_ES, 0.25)\n",
    "                  )/(norm.ppf(0.75) - norm.ppf(0.25))\n",
    "\n",
    "print(\"Bootstrap SE (nonparametric estimator) ES(0.1): %.6f\" % BootSE_ES)\n",
    "print(\"Bootstrap IQR SE (nonparametric estimator) ES(0.1): %.6f\" % Boot_IQR_SE_ES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (h)\n",
    "\n",
    "Find the 95% confidence intervals of VaR(0.1) and ES(0.1) using the nonparametric method in part (f).\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI using the bootstrap SE:  [-43.25341066534851, -33.13741976636861]\n",
      "95% CI using the bootstrap IQR SE:  [-43.15691123929683, -33.23391919242029]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap VaR Confidence Intervals\n",
    "## Using Boot-SE\n",
    "Boot_SE_CI095_VaR = [VaR_est - BootSE_VaR*1.96,\n",
    "                      VaR_est + BootSE_VaR*1.96]\n",
    "## Using IQR Boot-SE\n",
    "Boot_IQR_SE_CI095_VaR = [VaR_est - Boot_IQR_SE_VaR * 1.96,\n",
    "                          VaR_est + Boot_IQR_SE_VaR * 1.96]\n",
    "\n",
    "print(\"95% CI using the bootstrap SE: \", Boot_SE_CI095_VaR)\n",
    "print(\"95% CI using the bootstrap IQR SE: \", Boot_IQR_SE_CI095_VaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI using the bootstrap SE:  [-71.15960858113608, -53.91099478925781]\n",
      "95% CI using the bootstrap IQR SE:  [-71.21889846150403, -53.85170490888987]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap ES Confidence Intervals\n",
    "## Using Boot-SE\n",
    "Boot_SE_CI095_ES = [ES_est - BootSE_ES*1.96,\n",
    "                     ES_est + BootSE_ES*1.96]\n",
    "## Using IQR Boot-SE\n",
    "Boot_IQR_SE_CI095_ES = [ES_est - Boot_IQR_SE_ES * 1.96,\n",
    "                         ES_est + Boot_IQR_SE_ES * 1.96]\n",
    "\n",
    "print(\"95% CI using the bootstrap SE: \", Boot_SE_CI095_ES)\n",
    "print(\"95% CI using the bootstrap IQR SE: \", Boot_IQR_SE_CI095_ES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
